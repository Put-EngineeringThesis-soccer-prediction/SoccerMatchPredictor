{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from split_start import *\n",
    "from split_block import *\n",
    "from prepare_dataset import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = Path(os.getcwd()).parent\n",
    "sys.path.append(os.path.join(working_dir, 'Preprocessing\\\\'))\n",
    "\n",
    "from data_aggregator import *\n",
    "from season import *\n",
    "from parameters import *\n",
    "from team import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przygotowanie danych - pobranie przetworzonych danych do pamięci podręcznej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_last_matches = 3\n",
    "\n",
    "data_aggregator = DataAggregator()\n",
    "\n",
    "all_seasons, all_data_past =\\\n",
    "                    data_aggregator.get_data_for_seasons([Season.y2010, Season.y2011,\n",
    "                                                         Season.y2012, Season.y2013,\n",
    "                                                         Season.y2014, Season.y2015, Season.y2016], \n",
    "                                                         Parameters(no_last_matches=no_last_matches))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przygotowanie podstawowych wartości"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_seasons['match_date'] = pd.to_datetime(all_seasons['match_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_parameters = ['home_team_score',\n",
    "                        'away_team_score', \n",
    "                        'home_team_seasons_played',\n",
    "                        'away_team_seasons_played', \n",
    "                        'home_team_last_season_points',\n",
    "                        'away_team_last_season_points', \n",
    "                        'home_players_avg_age',\n",
    "                        'away_players_avg_age', \n",
    "                        'home_players_avg_rating',\n",
    "                        'away_players_avg_rating', \n",
    "                        'home_elo_rating', \n",
    "                        'away_elo_rating',\n",
    "                        'avg_home_win_odds', \n",
    "                        'avg_draw_odds', \n",
    "                        'avg_away_win_odds',\n",
    "                        'home_avg_corners', \n",
    "                        'away_avg_corners', \n",
    "                        'home_avg_shots',\n",
    "                        'away_avg_shots', \n",
    "                        'home_won_games', \n",
    "                        'away_won_games', \n",
    "                        'home_tied_games',\n",
    "                        'away_tied_games', \n",
    "                        'home_lost_games', \n",
    "                        'away_lost_games',\n",
    "                        'home_scored_goals', \n",
    "                        'away_scored_goals'\n",
    "                     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = prepare_dataset(all_seasons, list_of_parameters, all_data_past, add_direct = False, avg = 3, train_size = 0.9,\n",
    "                          test_size = 0.1, undersample = True, globalCS = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 603, 0: 521, 2: 595})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(dataset['y_train'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorytm Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = dataset['X_train']\n",
    "Ytrain = dataset['y_train']\n",
    "\n",
    "Xtest = dataset['X_test']\n",
    "Ytest = dataset['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'random_state': [10, 20, 40, 41, 42, 46, 50, 51, 56, 60, 70, 80],\n",
    "    'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "    'C': [0.2, 0.3, 0.7, 1.0, 1.5, 2.0],\n",
    "    'fit_intercept': [True, False],\n",
    "    'class_weight': ['balanced'],\n",
    "    'warm_start': [True, False],\n",
    "    'multi_class': ['auto'],\n",
    "    'solver': ['newton-cg', 'lbfgs', 'sag', 'saga'],\n",
    "    'max_iter': [2000]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticRegression = RandomizedSearchCV(estimator = LogisticRegression(), param_distributions = parameters, \\\n",
    "                                        n_jobs = -1, random_state = 42, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Najlepsze znalezione parametry: {'warm_start': True, 'solver': 'saga', 'random_state': 46, 'penalty': 'l2', 'multi_class': 'auto', 'max_iter': 2000, 'fit_intercept': True, 'class_weight': 'balanced', 'C': 0.7}\n"
     ]
    }
   ],
   "source": [
    "logisticRegression.fit(Xtrain, Ytrain)\n",
    "print(\"Najlepsze znalezione parametry:\", logisticRegression.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ypred = logisticRegression.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##################################\n",
      "Accuracy: \n",
      "0.5340314136125655\n",
      "\n",
      "##################################\n",
      "Precision, Recall and fscore:: \n",
      "(0.5280712050078247, 0.5379672692599584, 0.5278717801796683, None)\n"
     ]
    }
   ],
   "source": [
    "print('\\n##################################\\nAccuracy: ')\n",
    "\n",
    "print(metrics.accuracy_score(Ytest, Ypred))\n",
    "\n",
    "print('\\n##################################\\nPrecision, Recall and fscore:: ')\n",
    "\n",
    "print(metrics.precision_recall_fscore_support(Ytest, Ypred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poprawnie sklasyfikowane przykłady:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 23), (1, 40), (2, 39)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Poprawnie sklasyfikowane przykłady:\")\n",
    "sorted(Counter(Ytest[Ypred == Ytest]).items(), key = lambda el : el[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Błędnie sklasyfikowane przykłady:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 42), (1, 19), (2, 28)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Błędnie sklasyfikowane przykłady:\")\n",
    "sorted(Counter(Ytest[Ypred != Ytest]).items(), key = lambda el : el[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macierz pomyłek:\n",
      "[[23 18 24]\n",
      " [10 40  9]\n",
      " [15 13 39]]\n"
     ]
    }
   ],
   "source": [
    "confusion = metrics.confusion_matrix(Ytest, Ypred)\n",
    "print(\"Macierz pomyłek:\")\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nauczenie modelu na całym dostępnym zbiorze danych i jego zapis w celu wykorzystania w interaktywnym notebooku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "finalModel = logisticRegression.best_estimator_\n",
    "dataset_final = prepare_dataset(all_seasons, list_of_parameters, all_data_past, add_direct = False, avg = 3, train_size = 1.0,\n",
    "                          test_size = 0.0, undersample = True, globalCS = False)\n",
    "\n",
    "finalModel.fit(dataset_final['X_train'], dataset_final['y_train'])\n",
    "\n",
    "filename = 'logisticRegression.pkl'\n",
    "pickle.dump(finalModel, open(filename, \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
