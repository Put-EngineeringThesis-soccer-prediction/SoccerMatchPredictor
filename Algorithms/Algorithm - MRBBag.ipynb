{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from split_start import *\n",
    "from split_block import *\n",
    "from prepare_dataset import *\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from multi_imbalance.ensemble.mrbbagging import MRBBagging\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = Path(os.getcwd()).parent\n",
    "sys.path.append(os.path.join(working_dir, 'Preprocessing\\\\'))\n",
    "\n",
    "from data_aggregator import *\n",
    "from season import *\n",
    "from parameters import *\n",
    "from team import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przygotowanie danych - pobranie przetworzonych danych do pamięci podręcznej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_last_matches = 3\n",
    "\n",
    "data_aggregator = DataAggregator()\n",
    "\n",
    "all_seasons, all_data_past =\\\n",
    "                    data_aggregator.get_data_for_seasons([Season.y2010, Season.y2011,\n",
    "                                                         Season.y2012, Season.y2013,\n",
    "                                                         Season.y2014, Season.y2015, Season.y2016], \n",
    "                                                         Parameters(no_last_matches=no_last_matches))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przygotowanie podstawowych wartości"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_seasons['match_date'] = pd.to_datetime(all_seasons['match_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_parameters = ['home_team_score',\n",
    "                        'away_team_score', \n",
    "                        'home_team_seasons_played',\n",
    "                        'away_team_seasons_played', \n",
    "                        'home_team_last_season_points',\n",
    "                        'away_team_last_season_points', \n",
    "                        'home_players_avg_age',\n",
    "                        'away_players_avg_age', \n",
    "                        'home_players_avg_rating',\n",
    "                        'away_players_avg_rating', \n",
    "                        'home_elo_rating', \n",
    "                        'away_elo_rating',\n",
    "                        'avg_home_win_odds', \n",
    "                        'avg_draw_odds', \n",
    "                        'avg_away_win_odds',\n",
    "                        'home_avg_corners', \n",
    "                        'away_avg_corners', \n",
    "                        'home_avg_shots',\n",
    "                        'away_avg_shots', \n",
    "                        'home_won_games', \n",
    "                        'away_won_games', \n",
    "                        'home_tied_games',\n",
    "                        'away_tied_games', \n",
    "                        'home_lost_games', \n",
    "                        'away_lost_games',\n",
    "                        'home_scored_goals', \n",
    "                        'away_scored_goals'\n",
    "                     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = prepare_dataset(all_seasons, list_of_parameters, all_data_past, add_direct = True, avg = 3, train_size = 0.9,\n",
    "                          test_size = 0.1, undersample = False, globalCS = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 923, 0: 522, 2: 597})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(dataset['y_train'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorytm Multi-class Roughly Balanced Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = dataset['X_train']\n",
    "Ytrain = dataset['y_train']\n",
    "\n",
    "Xtest = dataset['X_test']\n",
    "Ytest = dataset['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrbag = MRBBagging(70, DecisionTreeClassifier(criterion = 'entropy', max_depth = 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MRBBagging(k=70,\n",
       "           learning_algorithm=DecisionTreeClassifier(criterion='entropy',\n",
       "                                                     max_depth=20))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrbag.fit(Xtrain.to_numpy(), Ytrain.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ypred = mrbag.predict(Xtest.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##################################\n",
      "Accuracy: \n",
      "0.4933920704845815\n",
      "\n",
      "##################################\n",
      "Precision, Recall and fscore:: \n",
      "(0.4784071729957806, 0.4758846807953951, 0.473063973063973, None)\n"
     ]
    }
   ],
   "source": [
    "print('\\n##################################\\nAccuracy: ')\n",
    "\n",
    "print(metrics.accuracy_score(Ytest, Ypred))\n",
    "\n",
    "print('\\n##################################\\nPrecision, Recall and fscore:: ')\n",
    "\n",
    "print(metrics.precision_recall_fscore_support(Ytest, Ypred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poprawnie sklasyfikowane przykłady:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 21), (1, 58), (2, 33)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Poprawnie sklasyfikowane przykłady:\")\n",
    "sorted(Counter(Ytest[Ypred == Ytest]).items(), key = lambda el : el[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Błędnie sklasyfikowane przykłady:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 43), (1, 40), (2, 32)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Błędnie sklasyfikowane przykłady:\")\n",
    "sorted(Counter(Ytest[Ypred != Ytest]).items(), key = lambda el : el[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macierz pomyłek:\n",
      "[[21 20 23]\n",
      " [17 58 23]\n",
      " [10 22 33]]\n"
     ]
    }
   ],
   "source": [
    "confusion = metrics.confusion_matrix(Ytest, Ypred)\n",
    "print(\"Macierz pomyłek:\")\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nauczenie modelu na całym dostępnym zbiorze danych i jego zapis w celu wykorzystania w interaktywnym notebooku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "finalModel = mrbag\n",
    "dataset_final = prepare_dataset(all_seasons, list_of_parameters, all_data_past, add_direct = True, avg = 3, train_size = 1.0,\n",
    "                          test_size = 0.0, undersample = False, globalCS = False)\n",
    "\n",
    "finalModel.fit(dataset_final['X_train'].to_numpy(), dataset_final['y_train'].to_numpy())\n",
    "\n",
    "filename = 'mrbbag.pkl'\n",
    "pickle.dump(finalModel, open(filename, \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
